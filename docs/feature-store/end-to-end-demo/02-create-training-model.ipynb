{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training  \n",
    "In this part we will show how using MLRun's **Feature Store** we can easily define a **Feature Vector** and create the dataset we need to run our training process.  \n",
    "\n",
    "We will see how to:\n",
    "- Combine multiple data sources to a single Feature Vector\n",
    "- Create training dataset\n",
    "- Create a model using an MLRun Hub function\n",
    "\n",
    "<img src=\"../../_static/images/feature_store_demo_diagram.png\" width=\"600px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Since our work is done in a this project scope, we will first want to define the project itself for all our MLRun work in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-05-23 09:34:08,315 [warning] Failed resolving version info. Ignoring and using defaults\n",
      "> 2021-05-23 09:34:10,899 [warning] Unable to parse server or client version. Assuming compatible: {'server_version': '0.6.4-rc3', 'client_version': 'unstable'}\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "from os import getenv\n",
    "\n",
    "project, _ = mlrun.set_environment(project='fsdemo', user_project=True)\n",
    "# location of the output data files\n",
    "data_path = f\"{getenv('V3IO_HOME_URL')}/demos/feature-store/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Vector  \n",
    "In this section we will create our Feature Vector.  \n",
    "The Feature vector will have a `name` so we can reference to it later via the UI or our serving function, and a list of `features` from the available FeatureSets.  We can add a feature from a feature set by adding `<FeatureSet>.<Feature>` to the list, or add `<FeatureSet>.*` to add all the FeatureSet's available features.  \n",
    "The `Label` is added explicitely from the available features so we will not look for it when serving in real-time (since it won't be available).\n",
    "\n",
    "By default, the first FeatureSet in the feature list will act as the spine. meaning that all the other features will be joined to it.  \n",
    "So for example, in this instance we use the early_sense sensor data as our spine, so for each early_sense event we will create produce a row in the resulted Feature Vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MLRun's Feature Store\n",
    "import mlrun.feature_store as fs\n",
    "\n",
    "# Define the featuer vector's name for future reference\n",
    "feature_vector_name = 'patient-deterioration'\n",
    "\n",
    "# Define the list of features in the feature vector\n",
    "features = ['early_sense.hr',\n",
    "            'early_sense.rr',\n",
    "            'early_sense.hr_h_avg_1h',\n",
    "            'early_sense.hr_d_avg_1d',\n",
    "            'early_sense.rr_h_avg_1h',\n",
    "            'early_sense.rr_d_avg_1d',\n",
    "            'early_sense.spo2_h_avg_1h',\n",
    "            'early_sense.spo2_d_avg_1d',\n",
    "            'early_sense.movements_h_avg_1h',\n",
    "            'early_sense.movements_d_avg_1d',\n",
    "            'early_sense.turn_count_h_avg_1h',\n",
    "            'early_sense.turn_count_d_avg_1d',\n",
    "            'early_sense.in_bed_h_avg_1h',\n",
    "            'early_sense.in_bed_d_avg_1d',\n",
    "            'early_sense.room',\n",
    "            'early_sense.spo2',\n",
    "            'early_sense.movements',\n",
    "            'early_sense.turn_count',\n",
    "            'early_sense.is_in_bed',\n",
    "            'early_sense.bed',\n",
    "            'measurements.agg_sp_0_0_avg_1h',\n",
    "            'measurements.agg_sp_0_1_avg_1h',\n",
    "            'measurements.agg_sp_0_2_avg_1h',\n",
    "            'measurements.agg_sp_1_0_avg_1h',\n",
    "            'measurements.agg_sp_1_1_avg_1h',\n",
    "            'measurements.agg_sp_1_2_avg_1h',\n",
    "            'measurements.agg_sp_2_0_avg_1h',\n",
    "            'measurements.agg_sp_2_1_avg_1h',\n",
    "            'measurements.agg_sp_2_2_avg_1h',\n",
    "            'patient_details.age',\n",
    "            'patient_details.age_mapped_toddler',\n",
    "            'patient_details.age_mapped_child',\n",
    "            'patient_details.age_mapped_adult',\n",
    "            'patient_details.age_mapped_elder',\n",
    "            ]\n",
    "\n",
    "# Define the feature vector\n",
    "fv = fs.FeatureVector(feature_vector_name, \n",
    "                      features, \n",
    "                      label_feature=\"labels.label\",\n",
    "                      description='Predict patient deterioration')\n",
    "\n",
    "# Save the feature vector in the Feature Store\n",
    "fv.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce training dataset as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RunDBError",
     "evalue": "Failed retrieving feature-set fsdemo-admin/labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.7/site-packages/mlrun/db/httpdb.py\u001b[0m in \u001b[0;36mapi_call\u001b[0;34m(self, method, path, error, params, body, json, headers, timeout)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: http://mlrun-api:8080/api/projects/fsdemo-admin/feature-sets/labels/references/latest",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRunDBError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b8dc6c207c30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# will return a pandas dataframe and save the dataset to parquet so a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# training job could train on it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_offline_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParquetTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# View dataset example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.7/site-packages/mlrun/feature_store/api.py\u001b[0m in \u001b[0;36mget_offline_features\u001b[0;34m(feature_vector, entity_rows, entity_timestamp_column, target, run_config, drop_columns)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mmerger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalFeatureMerger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     return merger.start(\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mentity_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_timestamp_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.7/site-packages/mlrun/feature_store/retrieval/local_merger.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, entity_rows, entity_timestamp_column, target, drop_columns)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mentity_timestamp_column\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mindex_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity_timestamp_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mfeature_set_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_set_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.7/site-packages/mlrun/feature_store/feature_vector.py\u001b[0m in \u001b[0;36mparse_features\u001b[0;34m(self, offline)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfeature_set\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_set_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 feature_set_objects[feature_set] = get_feature_set_by_uri(\n\u001b[0;32m--> 272\u001b[0;31m                     \u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                 )\n\u001b[1;32m    274\u001b[0m             \u001b[0mfeature_set_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_set_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.7/site-packages/mlrun/feature_store/common.py\u001b[0m in \u001b[0;36mget_feature_set_by_uri\u001b[0;34m(uri, project)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mdefault_project\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_project\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_versioned_object_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_project\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.7/site-packages/mlrun/db/httpdb.py\u001b[0m in \u001b[0;36mget_feature_set\u001b[0;34m(self, name, project, tag, uid)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"projects/{project}/feature-sets/{name}/references/{reference}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Failed retrieving feature-set {project}/{name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFeatureSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.7/site-packages/mlrun/db/httpdb.py\u001b[0m in \u001b[0;36mapi_call\u001b[0;34m(self, method, path, error, params, body, json, headers, timeout)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mf\"{method} {url}, error: {err}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRunDBError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRunDBError\u001b[0m: Failed retrieving feature-set fsdemo-admin/labels"
     ]
    }
   ],
   "source": [
    "# Import the Parquet Target so we can directly save our dataset as a file\n",
    "from mlrun.datastore.targets import ParquetTarget\n",
    "\n",
    "# Get offline feature vector\n",
    "# will return a pandas dataframe and save the dataset to parquet so a \n",
    "# training job could train on it\n",
    "dataset = fs.get_offline_features(feature_vector_name, target=ParquetTarget())\n",
    "\n",
    "# View dataset example\n",
    "df = dataset.to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View the dataset details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Vector URI for future reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv.uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload dataset to blob store\n",
    "\n",
    "You can optionally store the data to any file/object storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_parquet(data_path + 'patients.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use MLRun AutoML Training over Kubernetes  \n",
    "Here we will use MLRun to import a training function from our [functions hub](https://github.com/mlrun/functions) and run it on our cluster using our newly defined feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MLRun Serverless Training Function (from code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun.platforms import auto_mount\n",
    "\n",
    "# Import the SKLearn based training function from our functions hub\n",
    "fn = mlrun.import_function('hub://sklearn-classifier').apply(auto_mount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run AutoML Training Function over the cluster  \n",
    "We will use MLRun's HyperParameters mechanism to train 3 different models on the dataset and test them by their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Prepare the parameters list for the training function\n",
    "# We define 3 different models to test on our dataset\n",
    "model_list = {\"model_name\": ['patient_det_rf', 'patient_det_xgboost', 'patient_det_adaboost'],\n",
    "              \"model_pkg_class\": ['sklearn.ensemble.RandomForestClassifier',\n",
    "                                  'sklearn.ensemble.GradientBoostingClassifier',\n",
    "                                  'sklearn.ensemble.AdaBoostClassifier']}\n",
    "\n",
    "# Define the training task, including our feature vector, label and hyperparams definitions\n",
    "task = mlrun.new_task('training', \n",
    "                      inputs={'dataset': f'store://feature-vectors/{project}/{feature_vector_name}'},\n",
    "                      params={'label_column': 'label'}\n",
    "                     )\n",
    "task.with_hyper_params(model_list, strategy='list', selector='max.accuracy')\n",
    "\n",
    "# Run the function \n",
    "fn.spec.image = 'mlrun/ml-models'\n",
    "run = fn.run(task, local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View the run outputs, including result metrics and artifacts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View the training dataset status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.get_feature_vector(f'{project}/{feature_vector_name}').status.targets['parquet'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "You've completed the training process. Proceed to [Part 3](03-deploy-serving-model.ipynb) to deploy the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
